harvest_data:
  description: >
    Fetch political/policy headlines and cache to raw_news.json.
  use_llm: false            # 👈 skip LLM completely
  tool:
    name: PoliticalNewsTool
    inputs:
      symbol: "{symbol}"
      query: "{query}"
      days_back: "{days_back}"
  expected_output: >
    ✅ Saved the output: raw_news.json

enhance_forecast:
  description: >
    You are given the full JSON dump for one symbol in `{{merged_json}}`.
    1. Parse the fields:
         • patterns               (list)
         • news_headlines         (list)
         • stock_data             (list of OHLCV dicts)
         • next_prediction        (dict with direction / confidence / O H L C)
    2. Read the headlines and assign **headline_sentiment** ∈ [-1,1].
    3. Adjust `next_prediction`:
         • If sentiment contradicts technical bias, lower confidence
         • If sentiment reinforces bias, raise confidence
       Adjust O/H/L/C based on the analysis.
    4. Return a new JSON object **with the same keys** but an updated
       `next_prediction`. Also output a 2-3 sentence markdown narrative
       explaining the adjustment.
  inputs:
    symbol: "{symbol}"
    merged_json: "{merged_json}"
  expected_output: >
    ✅ Successfully wrote enhanced_forecast_{symbol}.json and
    enhanced_forecast_{symbol}.md


#fundamental_analysis:
#  description: >
#    For each symbol, perform a **standalone fundamental valuation**.
#
#    1. **Valuation Metrics**:
#       - Calculate: P/E, EV/EBITDA, PEG ratio, Price-to-Book (P/B), and dividend yield.
#       - Include the current value, 1-year median, 5-year median, and z-score if available.
#       - Use EV and EBITDA approximations based on available historical financials.
#
#    2. **Benchmarking**:
#       - Compare each metric to:
#         a. the symbol’s own 1-year and 5-year history.
#         b. sector peer group averages (provide sector if known or infer from metadata).
#       - Highlight where metrics deviate significantly (±1.5 standard deviations or more).
#
#    3. **Catalyst Detection**:
#       - Identify recent earnings beats/misses.
#       - Note guidance revisions, dividend announcements, insider transactions, or major filings.
#       - Indicate whether the catalyst is likely to influence valuation short-term.
#
#    4. **Drift Estimation**:
#       - Predict **intraday drift** using recent price action vs. fundamental surprises.
#       - If no clear signal, indicate “Neutral” drift with rationale.
#
#    5. **Output Schema Requirements**:
#       - Each symbol must be represented **independently**.
#       - The output MUST contain:
#         - `symbol`: ticker (e.g. NVDA, SPY)
#         - `valuation_metrics`: dict of all computed metrics
#         - `benchmarks`: dict of comparisons (1y, 5y, sector)
#         - `catalysts`: list of detected events
#         - `predicted_trend`: one of ['Up', 'Down', 'Neutral']
#         - `confidence`: float between 0 and 1
#         - `rationale`: short paragraph explaining the above
#
#    6. **Non-Aggregation Rule**:
#       - DO NOT summarize across symbols.
#       - DO NOT generalize patterns or group insights — each ticker is evaluated on its own merit.
#
#    Symbols to analyze:
#      • ETFs: {etf_symbols}
#      • Equities: {equity_symbols}
#
#  expected_output: >
#    fundamental_summary.json as a JSON array, where each object includes:
#      - symbol
#      - valuation_metrics
#      - benchmarks
#      - catalysts
#      - predicted_trend
#      - confidence
#      - rationale
#
#    Example:
#    ```json
#    {
#      "symbol": "NVDA",
#      "valuation_metrics": { "P/E": 42.1, "EV/EBITDA": 28.4, ... },
#      "benchmarks": { "1y_median": { ... }, "5y_median": { ... }, "sector": { ... } },
#      "catalysts": ["Q1 earnings beat", "Raised Q2 revenue guidance"],
#      "predicted_trend": "Up",
#      "confidence": 0.86,
#      "rationale": "Valuation is rich but supported by strong earnings and raised guidance. Sector-relative PEG is still below average."
#    }
#    ```
#
#  agent: valuation_engine_agent
#
#technical_analysis:
#  description: >
#    Analyze the last 5 OHLCV candles for each provided symbol (ETF or equity).
#    Your analysis must be structured, symbol-by-symbol, with no summarization across assets.
#
#    For each symbol:
#      1. Parse the OHLCV data into 5 most recent entries.
#      2. Format each candle as:
#         - DATE: O=X H=Y L=Z C=W Vol=V
#      3. Apply technical analysis indicators:
#         - RSI (Relative Strength Index)
#         - MACD (Moving Average Convergence Divergence)
#         - Bollinger Bands
#         - Trendline / price drift
#         - Pattern detection (e.g., head and shoulders, double top/bottom, flags, wedges)
#      4. Provide directional interpretation:
#         - `trend`: one of “Uptrend”, “Downtrend”, “Sideways”
#         - `momentum_score`: float between -1.0 (strong bear) to +1.0 (strong bull)
#         - `pattern_notes`: any detected patterns or signal commentary
#      5. Call ForecastSignalTool on each ticker using the data in `close_price_map`.
#
#    ⚠️ Do NOT aggregate across symbols.
#    Each asset is evaluated independently.
#
#    ---
#    Input:
#      You are provided with:
#      - A formatted context variable called `formatted_ohlc_data`
#        Example:
#          **SPY** last 5 candles:
#          - 2025-06-13: O=598.5 H=601.85 L=595.48 C=597 Vol=89,505,996
#          - ...
#          **NVDA** last 5 candles:
#          - ...
#      - Raw tickers:
#        • ETFs: {etf_symbols}
#        • Equities: {equity_symbols}
#
#    🛠 Tools available:
#      - MarketPriceTool: fetches intraday or daily price data
#      - ForecastSignalTool: generates directional forecasts
#      - OHLCFormatterTool: standardizes candle layout
#      - (Optional) You may refer to classic TA indicators or signal libraries.
#
#    Formatting Rules:
#      - Markdown only
#      - Use headings (`## SYMBOL`) per asset
#      - List candles first, then indicators and interpretation
#      - Always include each symbol, even if no patterns found
#      - If no data is available, state “No price data available for SYMBOL”
#
#  expected_output: >
#    A Markdown report that includes:
#      • Last 5 OHLCV candles per symbol, properly formatted
#      • RSI, MACD, Bollinger Band positioning
#      • Pattern analysis
#      • Interpretation with trend, momentum_score and pattern_notes
#      • A separate section per symbol using `## SYMBOL` header
#
#    Example:
#    ## SPY
#    - 2025-06-13: O=598.5 H=601.85 L=595.48 C=597 Vol=89,505,996
#    - ...
#    **Indicators**:
#    - RSI: 62 (neutral)
#    - MACD: Slightly bullish crossover detected
#    - Bollinger: Approaching upper band
#    **Interpretation**:
#    - trend: Uptrend
#    - momentum_score: +0.4
#    - pattern_notes: Ascending triangle breakout in progress
#
#    Repeat this structure for all symbols.
#
#  agent: pattern_scanner_agent

compose_report:
  description: >
    Format the JSON file at
    `output/pattern_analysis_results_{symbol}.json` into a single Markdown
    section for that symbol. If the file is missing, output the string
    “No data available for {symbol}.”
  use_llm: false
  tool:
    name: MarkdownFormatterTool
  inputs:
      json_path: "output/pattern_analysis_results_{symbol}.json"
  expected_output: >
      A Markdown string for {symbol}


compose_report_followup:
  description: >
    Format the contents of `output/pattern_analysis_results_{symbol}.json`
    into a clean Markdown section for the remaining symbols. If the file is
    missing, write “No data available for {symbol}.” Use the provided tool
    only; do not invoke an LLM.
  use_llm: false
  tool:
    name: MarkdownFormatterTool
    inputs:
      json_path: "output/pattern_analysis_results_{symbol}.json"
  expected_output: >
    A Markdown string for {symbol} appended to the main report.